{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(str(os.path.abspath('')), \"..\", \"..\"))\n",
    "\n",
    "from src.utils.losses import DiceLoss, DiceBCELoss\n",
    "# from src.utils.dice_coef import DiceCoef\n",
    "from src.utils.set_seed import seed_torch\n",
    "from src.utils.transforms import get_transform\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import albumentations as A\n",
    "from torch.nn import functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import Unet, FPN, UnetPlusPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class CFG:\n",
    "    data = 512 #256\n",
    "#     debug=False\n",
    "#     apex=False\n",
    "#     print_freq=100\n",
    "    num_workers=4\n",
    "    img_size=512 # appropriate input size for encoder \n",
    "#     epoch=60 # Change epochs\n",
    "    criterion= 'DiceBCELoss' #'DiceBCELoss' # ['DiceLoss', 'Hausdorff', 'Lovasz']\n",
    "#     lr=1e-3\n",
    "#     min_lr=1e-5\n",
    "    batch_size=1\n",
    "#     weight_decay=1e-5\n",
    "    seed=251096\n",
    "#     n_fold=5\n",
    "#     trn_fold=[0, 1, 2, 3, 4]\n",
    "#     train=True\n",
    "#     inference=False\n",
    "#     optimizer = 'Adam'\n",
    "#     T_0=10\n",
    "    # N=5 \n",
    "    # M=9\n",
    "#     T_max=10\n",
    "#     factor=0.1\n",
    "#     patience=4\n",
    "#     eps=1e-8\n",
    "#     smoothing=1\n",
    "#     train_transform_type = 'strong'\n",
    "    valid_transform_type = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_THRESHOLD = 0.4\n",
    "dir_df = pd.read_csv(\"dir_df.csv\")\n",
    "seed_torch(seed=CFG.seed)\n",
    "valid_transform = get_transform(img_size=CFG.img_size, transform_type=CFG.valid_transform_type)\n",
    "RESIZED_DATA_DIR = '../../../../hdd/storage/kidney_segmentation/working_kaggle/resized_data_kaggle_lafoss/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self,df, train='train', transform=True):\n",
    "        ids = df.id.values\n",
    "        #kf = KFold(n_splits=nfolds,random_state=SEED,shuffle=True)\n",
    "        #ids = set(ids[list(kf.split(ids))[fold][0 if train else 1]])\n",
    "        if CFG.data==1024:\n",
    "            self.fnames = [fname for fname in os.listdir(RESIZED_DATA_DIR + '1024*1024/train/') if fname.split('_')[0] in ids]\n",
    "        elif CFG.data==512:\n",
    "            self.fnames = [fname for fname in os.listdir(RESIZED_DATA_DIR + '512*512/train/') if fname.split('_')[0] in ids]\n",
    "        elif CFG.data==256:\n",
    "            self.fnames = [fname for fname in os.listdir(RESIZED_DATA_DIR + '256*256/train/') if fname.split('_')[0] in ids]\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "#         print(self.fnames)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        if CFG.data==1024:\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(RESIZED_DATA_DIR + '1024*1024/train/',fname)), cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(os.path.join(RESIZED_DATA_DIR + '1024*1024/masks',fname),cv2.IMREAD_GRAYSCALE)\n",
    "        elif CFG.data==512:\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(RESIZED_DATA_DIR + '512*512/train/',fname)), cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(os.path.join(RESIZED_DATA_DIR + '512*512/masks',fname),cv2.IMREAD_GRAYSCALE)\n",
    "        elif CFG.data==256:\n",
    "            img = cv2.cvtColor(cv2.im../read(os.path.join(RESIZED_DATA_DIR + '256*256/train/',fname)), cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(os.path.join(RESIZED_DATA_DIR + '256*256/masks',fname),cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if self.train == 'train':\n",
    "            if self.transform == True:\n",
    "                augmented = train_transform(image=img,mask=mask)\n",
    "                img,mask = augmented['image'],augmented['mask']\n",
    "                    \n",
    "        elif self.train == 'val':\n",
    "            transformed = valid_transform(image=img,mask=mask)\n",
    "            img,mask = transformed['image'],transformed['mask']\n",
    "            \n",
    "        img = img.type('torch.FloatTensor')\n",
    "        img = img/255\n",
    "        mask = mask.type('torch.FloatTensor')\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afa5e8098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0486052bb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afa5e8098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afa5e8098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>095bf7a1f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>b2dc8411c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>c68fe75ea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9581</th>\n",
       "      <td>095bf7a1f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9582</th>\n",
       "      <td>095bf7a1f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9583</th>\n",
       "      <td>4ef6695ce</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9584 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  Folds\n",
       "0     afa5e8098      2\n",
       "1     0486052bb      0\n",
       "2     afa5e8098      2\n",
       "3     afa5e8098      2\n",
       "4     095bf7a1f      2\n",
       "...         ...    ...\n",
       "9579  b2dc8411c      1\n",
       "9580  c68fe75ea      1\n",
       "9581  095bf7a1f      2\n",
       "9582  095bf7a1f      2\n",
       "9583  4ef6695ce      0\n",
       "\n",
       "[9584 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if CFG.data==1024:\n",
    "#     directory_list = os.listdir(RESIZED_DATA_DIR + '1024*1024/train')\n",
    "# elif CFG.data==512:\n",
    "#     directory_list = os.listdir(RESIZED_DATA_DIR + '512*512/train')\n",
    "# elif CFG.data==256:\n",
    "#     directory_list = os.listdir(RESIZED_DATA_DIR + '256*256/train')\n",
    "# directory_list = [fnames.split('_')[0] for fnames in directory_list]\n",
    "# dir_df = pd.DataFrame(directory_list, columns=['id'])\n",
    "dir_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCoef(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceCoef, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # print(\"1 inputs = \", inputs)\n",
    "#         inputs = F.sigmoid(inputs)\n",
    "        # print(\"2 inputs = \", inputs)\n",
    "        # print('targets = ', targets)\n",
    "        # flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        inputs_new = inputs > PREDICTION_THRESHOLD\n",
    "        # print(\"3 inputs = \", inputs)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        intersection_new = (inputs_new * targets).sum()\n",
    "        dice_new = (2. * intersection_new + smooth) / (inputs_new.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return dice, dice_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HuBMAPMetric(outputs, targets):\n",
    "#     model.to(device)\n",
    "#     images = images.to(device)\n",
    "#     targets = targets.to(device)\n",
    "#     outputs = model(images)\n",
    "    criterion = DiceCoef()\n",
    "    metric = criterion(outputs, targets)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuBMAPEffnetB4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HuBMAPEffnetB4, self).__init__()\n",
    "        self.cnn_model = smp.Unet('efficientnet-b4', classes=1)\n",
    "        \n",
    "        #self.cnn_model.decoder.blocks.append(self.cnn_model.decoder.blocks[-1])\n",
    "        #self.cnn_model.decoder.blocks[-2] = self.cnn_model.decoder.blocks[-3]\n",
    "    \n",
    "    def forward(self, imgs):\n",
    "        img_segs = self.cnn_model(imgs)\n",
    "        return img_segs\n",
    "    \n",
    "class HuBMAPResnet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HuBMAPResnet34, self).__init__()\n",
    "        self.cnn_model = smp.Unet('resnet34', classes=1)\n",
    "        \n",
    "        #self.cnn_model.decoder.blocks.append(self.cnn_model.decoder.blocks[-1])\n",
    "        #self.cnn_model.decoder.blocks[-2] = self.cnn_model.decoder.blocks[-3]\n",
    "    \n",
    "    def forward(self, imgs):\n",
    "        img_segs = self.cnn_model(imgs)\n",
    "        return img_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_prediction(img, models, tta = True):\n",
    "    pred = None\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            p_tta = None\n",
    "            p = model(img)\n",
    "            p = torch.sigmoid(p).detach()\n",
    "            if p_tta is None:\n",
    "                p_tta = p\n",
    "            else:\n",
    "                p_tta += p\n",
    "            if tta:\n",
    "                #x,y,xy flips as TTA\n",
    "                flips = [[-1],[-2],[-2,-1]]\n",
    "                for f in flips:\n",
    "                    imgf = torch.flip(img, f)\n",
    "                    p = model(imgf)\n",
    "                    p = torch.flip(p, f)\n",
    "                    p_tta += torch.sigmoid(p).detach()\n",
    "                p_tta /= (1+len(flips))\n",
    "            if pred is None:\n",
    "                pred = p_tta\n",
    "            else:\n",
    "                pred += p_tta\n",
    "    pred /= len(models)\n",
    "#     print('pred = ', pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(device, validloader, models):\n",
    "    t = time.time()\n",
    "    total_loss = 0\n",
    "    total_metric = 0\n",
    "    total_metric_new = 0\n",
    "    for step, (images, targets) in enumerate(validloader):\n",
    "        images = images.to(device)\n",
    "        outputs = Make_prediction(images, models)\n",
    "#         print(outputs)\n",
    "\n",
    "#         print(outputs.shape)\n",
    "        outputs = outputs\n",
    "        metric, metric_new = HuBMAPMetric(outputs.cpu(), targets)\n",
    "        total_metric += metric\n",
    "        total_metric_new += metric_new\n",
    "\n",
    "        if ((step+1)%10==0 or (step+1)==len(validloader)):\n",
    "            print(\n",
    "#                     f'loss: {total_loss/len(validloader):.4f}, ' + \\\n",
    "                    f'dice_coef: {total_metric/len(validloader):.4f}, ' + \\\n",
    "                    f'dice_coef_new: {total_metric_new/len(validloader):.4f}, ' + \\\n",
    "                    f'time: {(time.time() - t):.4f}', end= '\\r' if (step + 1) != len(validloader) else '\\n'\n",
    "                )\n",
    "    print(\"len(validloader) = \", len(validloader))\n",
    "    return total_metric_new/len(validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model(name, fold_number):\n",
    "    weight_path = f\"{name}/FOLD-{fold_number}-model.pth\"\n",
    "    state_dict = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "    if name == 'resnet34':\n",
    "        model = HuBMAPResnet34().to(device)\n",
    "    if name == 'effnetb4':\n",
    "        model = HuBMAPEffnetB4().to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    del state_dict\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_coef: 0.3685, dice_coef_new: 0.9157, time: 177.3745\n",
      "len(validloader) =  1884\n",
      "dice_coef: 0.1996, dice_coef_new: 0.9434, time: 181.3604\n",
      "len(validloader) =  1937\n",
      "dice_coef: 0.3274, dice_coef_new: 0.9227, time: 181.2905\n",
      "len(validloader) =  1916\n",
      "dice_coef: 0.4182, dice_coef_new: 0.9291, time: 184.5536\n",
      "len(validloader) =  1958\n",
      "dice_coef: 0.3296, dice_coef_new: 0.9490, time: 179.3238\n",
      "len(validloader) =  1889\n",
      "cv_dice =  0.931973147392273\n"
     ]
    }
   ],
   "source": [
    "FOLDS = [0, 1, 2, 3, 4]\n",
    "scores = []\n",
    "for fold_number in FOLDS:\n",
    "    models = []\n",
    "    model34 = read_model('resnet34', fold_number)\n",
    "    modelb4 = read_model('effnetb4', fold_number)\n",
    "    models.append(model34)\n",
    "    models.append(modelb4)\n",
    "    \n",
    "    dir_df = pd.read_csv(\"dir_df.csv\")\n",
    "#     dir_df = dir_df[~dir_df['id'].str.contains('d488c759a')]\n",
    "    dir_df = dir_df[dir_df.Folds == fold_number]\n",
    "    TEST_IMAGES = list(dir_df.id.unique())\n",
    "    \n",
    "    val_ids = pd.DataFrame({'id': TEST_IMAGES})\n",
    "    val_ds = HuBMAPDataset(val_ids, train='val', transform=True)\n",
    "    validloader = DataLoader(val_ds, batch_size=CFG.batch_size, pin_memory=True, shuffle=False, num_workers=4)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        score = valid(device, validloader, models)\n",
    "    \n",
    "    scores.append(score.to('cpu').item())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "scores = np.array(scores)\n",
    "cv_dice = scores.mean()\n",
    "print(\"cv_dice = \", cv_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubmap_venv",
   "language": "python",
   "name": "hubmap_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
