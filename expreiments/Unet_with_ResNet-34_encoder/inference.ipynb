{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import pdb\n",
    "import glob\n",
    "import pytz\n",
    "import warnings\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import tifffile as tiff\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose,\n",
    "    CenterCrop,\n",
    "    CLAHE,\n",
    "    Resize,\n",
    "    Normalize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 512, 512\n",
    "reduce = 2\n",
    "THRESHOLD = 0.40\n",
    "window = 1024\n",
    "min_overlap = 128\n",
    "PATH_TO_KAGGLE_INPUT = \"HERE_DEFINE_PATH_TO_KAGGLE_INPUT/\"\n",
    "DATA = PATH_TO_KAGGLE_INPUT + 'test/'\n",
    "MODELS = [\n",
    "    \"weights/FOLD-0-model.pth\",\n",
    "    \"weights/FOLD-1-model.pth\",\n",
    "    \"weights/FOLD-2-model.pth\",\n",
    "    \"weights/FOLD-3-model.pth\",\n",
    "    \"weights/FOLD-4-model.pth\"\n",
    "]\n",
    "df_sample = pd.read_csv(PATH_TO_KAGGLE_INPUT + 'sample_submission.csv')\n",
    "batch_size = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #functions to convert encoding to mask and mask to encoding\n",
    "# def enc2mask(encs, shape):\n",
    "#     img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "#     for m,enc in enumerate(encs):\n",
    "#         if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "#         s = enc.split()\n",
    "#         for i in range(len(s)//2):\n",
    "#             start = int(s[2*i]) - 1\n",
    "#             length = int(s[2*i+1])\n",
    "#             img[start:start+length] = 1 + m\n",
    "#     return img.reshape(shape).T\n",
    "\n",
    "# def mask2enc(mask, n=1):\n",
    "#     pixels = mask.T.flatten()\n",
    "#     encs = []\n",
    "#     for i in range(1,n+1):\n",
    "#         p = (pixels == i).astype(np.int8)\n",
    "#         if p.sum() == 0: encs.append(np.nan)\n",
    "#         else:\n",
    "#             p = np.concatenate([[0], p, [0]])\n",
    "#             runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "#             runs[1::2] -= runs[::2]\n",
    "#             encs.append(' '.join(str(x) for x in runs))\n",
    "#     return encs\n",
    "\n",
    "#https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n",
    "#with transposed mask\n",
    "def rle_encode_less_memory(img):\n",
    "    #the image should be transposed\n",
    "    pixels = img.T.flatten()\n",
    "    \n",
    "    # This simplified method requires first and last pixel to be zero\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    \n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagenet statistics Mean and variance\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "\n",
    "# def get_transforms(mean, std):\n",
    "#     list_transforms = [Resize(height=height, width=width, p=1.0,\n",
    "#                              interpolation=cv2.INTER_AREA,\n",
    "#                              )]\n",
    "#     list_transforms.extend(\n",
    "#         [\n",
    "#             Normalize(mean=mean, std=std, p=1.0),\n",
    "#             ToTensorV2(),\n",
    "#         ]\n",
    "#     )\n",
    "#     list_trfms = Compose(list_transforms)\n",
    "#     return list_trfms\n",
    "def get_transforms():\n",
    "    transform = A.Compose([\n",
    "                A.Resize(height, width, p=1.0),\n",
    "                ToTensorV2()\n",
    "            ], p=1.0)\n",
    "    return transform\n",
    "\n",
    "def make_grid(shape, window=256, min_overlap=32):\n",
    "    \"\"\"\n",
    "        Return Array of size (N,4), where N - number of tiles,\n",
    "        2nd axis represente slices: x1,x2,y1,y2 \n",
    "    \"\"\"\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n",
    "    \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n",
    "    return slices.reshape(nx*ny,4)\n",
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        if self.data.count != 3:\n",
    "            subdatasets = self.data.subdatasets\n",
    "            self.layers = []\n",
    "            if len(subdatasets) > 0:\n",
    "                for i, subdataset in enumerate(subdatasets, 0):\n",
    "                    self.layers.append(rasterio.open(subdataset))\n",
    "        self.shape = self.data.shape\n",
    "        self.mask_grid = make_grid(self.data.shape, window=window, min_overlap=min_overlap)\n",
    "        self.transforms = get_transforms()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mask_grid)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x1, x2, y1, y2 = self.mask_grid[idx]\n",
    "        if self.data.count == 3:\n",
    "            img = data.read([1,2,3], window=Window.from_slices((x1, x2), (y1, y2)))\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        else:\n",
    "            img = np.zeros((window, window, 3), dtype=np.uint8)\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                img[:,:,i] = layer.read(window=Window.from_slices((x1,x2),(y1,y2)))\n",
    "        augmented = self.transforms(image=img)\n",
    "        img = augmented['image']\n",
    "        vetices = torch.tensor([x1, x2, y1, y2])\n",
    "        img = img.type('torch.FloatTensor')\n",
    "        img = img / 255.0\n",
    "#         print('img = ', img)\n",
    "        return img, vetices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_model = smp.Unet('resnet34', classes=1)\n",
    "print(base_model)\n",
    "class HuBMAP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HuBMAP, self).__init__()\n",
    "        self.cnn_model = base_model\n",
    "        \n",
    "        #self.cnn_model.decoder.blocks.append(self.cnn_model.decoder.blocks[-1])\n",
    "        #self.cnn_model.decoder.blocks[-2] = self.cnn_model.decoder.blocks[-3]\n",
    "    \n",
    "    def forward(self, imgs):\n",
    "        img_segs = self.cnn_model(imgs)\n",
    "        return img_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for path in MODELS:\n",
    "    state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "#     model = smp.Unet('resnet34', classes=1\n",
    "#                      , encoder_weights=None\n",
    "#                     )\n",
    "    model = HuBMAP().to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "del state_dict\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_prediction(img, tta = False):\n",
    "    pred = None\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            p_tta = None\n",
    "            p = model(img)\n",
    "            p = torch.sigmoid(p).detach()\n",
    "            if p_tta is None:\n",
    "                p_tta = p\n",
    "            else:\n",
    "                p_tta += p\n",
    "            if tta:\n",
    "                #x,y,xy flips as TTA\n",
    "                flips = [[-1],[-2],[-2,-1]]\n",
    "                for f in flips:\n",
    "                    imgf = torch.flip(img, f)\n",
    "                    p = model(imgf)\n",
    "                    p = torch.flip(p, f)\n",
    "                    p_tta += torch.sigmoid(p).detach()\n",
    "                p_tta /= (1+len(flips))\n",
    "            if pred is None:\n",
    "                pred = p_tta\n",
    "            else:\n",
    "                pred += p_tta\n",
    "        pred /= len(models)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-b57d04c1b50c>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf355be83975428e9d03d687d1c927ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greylord/hubmap_kidney/hubmap_venv/lib/python3.8/site-packages/rasterio/__init__.py:207: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "names, predictions = [],[]\n",
    "for idx, row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n",
    "    imageId = row['id']\n",
    "    data = rasterio.open(os.path.join(DATA, imageId+'.tiff'), transform = identity, num_threads='all_cpus')\n",
    "    preds = np.zeros(data.shape, dtype=np.uint8)\n",
    "    dataset = HuBMAPDataset(data)\n",
    "    dataloader = DataLoader(dataset, batch_size, num_workers=0, shuffle=False, pin_memory=True)\n",
    "    for i, (img, vertices) in enumerate(dataloader):\n",
    "        img = img.to(device)\n",
    "        pred = Make_prediction(img)\n",
    "        pred = pred.squeeze().cpu().numpy()\n",
    "        vertices = vertices.numpy()\n",
    "        for p, vert in zip(pred, vertices):\n",
    "            x1, x2, y1, y2 = vert\n",
    "            p = cv2.resize(p, (window, window))\n",
    "            preds[x1:x2,y1:y2] += (p > THRESHOLD).astype(np.uint8)\n",
    "    preds = (preds > 0.5).astype(np.uint8)\n",
    "    #convert to rle\n",
    "    rle = rle_encode_less_memory(preds)\n",
    "    names.append(imageId)\n",
    "    predictions.append(rle)\n",
    "    del preds, dataset, dataloader\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':names,'predicted':predictions})\n",
    "df.to_csv('submission/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ec3f1bb9</td>\n",
       "      <td>60690334 26 60714315 38 60738300 46 60762286 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3589adb90</td>\n",
       "      <td>68600119 13 68600139 10 68629519 67 68658948 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d488c759a</td>\n",
       "      <td>329870451 5 329917109 8 329963768 11 330010428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa05346ff</td>\n",
       "      <td>52795267 4 52825971 34 52856688 40 52887404 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57512b7f1</td>\n",
       "      <td>230242896 3 230276135 9 230309374 13 230342614...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          predicted\n",
       "0  2ec3f1bb9  60690334 26 60714315 38 60738300 46 60762286 5...\n",
       "1  3589adb90  68600119 13 68600139 10 68629519 67 68658948 7...\n",
       "2  d488c759a  329870451 5 329917109 8 329963768 11 330010428...\n",
       "3  aa05346ff  52795267 4 52825971 34 52856688 40 52887404 47...\n",
       "4  57512b7f1  230242896 3 230276135 9 230309374 13 230342614..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubmap_venv",
   "language": "python",
   "name": "hubmap_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
